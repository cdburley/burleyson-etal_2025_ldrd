{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e071b84",
   "metadata": {},
   "source": [
    "# Train and Run the Underlying MLP Models in TELL Using Evolving Time Windows\n",
    "\n",
    "This notebook is the core tool for training and running the evolving sets of multilayer perceptron (MLP) models used in this experiment. It assumes that the base Total ELectricity Loads (TELL) model has already been installed and the datasets updated to include the most recent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db683a-70a2-4f89-a1d6-4c6d5f180272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start by importing the TELL package and information about your operating system:\n",
    "import os \n",
    "import tell\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e8454-24e1-44f2-bfb7-2f6499e11321",
   "metadata": {},
   "source": [
    "## Set the Directory Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a9e7b-a9a7-4fdd-957e-2bb5f063afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the top-level directory to store the trained MLP models:\n",
    "cleaned_ba_data_output_dir =  '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/cleaned_historical_data/'\n",
    "ba_to_process_input_dir =  '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/'\n",
    "weather_data_input_dir =  '/Users/burl878/Documents/Code/code_repos/tell/tell/tell_data/sample_forcing_data/historical_weather'\n",
    "model_output_directory = '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/trained_mlp_models/'\n",
    "prediction_output_directory = '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/mlp_projections/'\n",
    "composite_output_directory = '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/composite_projections/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359376d2-5a07-4868-892f-36db5931399d",
   "metadata": {},
   "source": [
    "## Set the List of Balancing Authorities to Analyze\n",
    "\n",
    "BAs used in this analysis are controlled by a master file `balancing_authorities_modeled.yml` stored in the `/data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be839966-941b-4902-af8e-5de92b71b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the yml file into a dictionary:\n",
    "with open((ba_to_process_input_dir + 'balancing_authority_modeled.yml'), 'r') as yml:\n",
    "     ba_list = yaml.load(yml, Loader=yaml.FullLoader)\n",
    "     bas = [i for i in ba_list.keys()]\n",
    "\n",
    "# Return the list of BAs to process/plot:\n",
    "bas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a037554",
   "metadata": {},
   "source": [
    "## MLP Model Training\n",
    "\n",
    "The MLP models underpinning TELL use temporal variations in weather to project hourly demand. More information about this approach is in the MLP section of the `tell` [User Guide](https://immm-sfa.github.io/tell/user_guide.html). The default settings for the MLP model training steps are included in the `mlp_settings.yml` file included in the data folder of the `tell` repository. By default the MLP models are trained on data from 2016-2018 and evaluated using data from 2019. The time windows for training and evaluating the models can be modified by altering the `start_time`, `end_time`, and `split_datetime` parameters when calling the `tell.train` function. The workflow does not change the default MLP parameters (e.g., hidden layer sizes, maximum number of iterations, etc.) from TELL. Those could be modified in theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b742f-c5e9-487b-be65-ee3f25199ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For more information about the training of predictive models you can call the help function:\n",
    "help(tell.train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccddc4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the MLP training step for a single BA to get a feel of the functionality:\n",
    "prediction_df, validation_df = tell.train(region = 'CISO',\n",
    "                                          data_dir = cleaned_ba_data_output_dir,\n",
    "                                          start_time = '2018-01-01 00:00:00',\n",
    "                                          end_time = '2020-12-31 23:00:00',\n",
    "                                          split_datetime = '2019-12-31 23:00:00',\n",
    "                                          save_model = True,\n",
    "                                          model_output_directory = '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/trained_mlp_models/MLP1/')\n",
    "\n",
    "# View the head of the prediction dataframe that contains the time-series of projected load in the evaluation year:\n",
    "display(prediction_df.head(10))\n",
    "\n",
    "# View validation dataframe that contains error statistics for the trained model:\n",
    "validation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df28891-b1a0-430a-93b4-afa1e448027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training iteratively across all training windows and BAs:\n",
    "for model in ['MLP1', 'MLP2', 'MLP3', 'MLP4', 'MLP5', 'MLP6']:\n",
    "\n",
    "    # Set the training and evaluation periods for the specific model training window:\n",
    "    if model == 'MLP1':\n",
    "       start_time_model = '2016-01-01 00:00:00'\n",
    "       end_time_model = '2018-12-31 23:00:00'\n",
    "       split_datetime_model = '2017-12-31 23:00:00'\n",
    "    if model == 'MLP2':\n",
    "       start_time_model = '2017-01-01 00:00:00'\n",
    "       end_time_model = '2019-12-31 23:00:00'\n",
    "       split_datetime_model = '2018-12-31 23:00:00'\n",
    "    if model == 'MLP3':\n",
    "       start_time_model = '2018-01-01 00:00:00'\n",
    "       end_time_model = '2020-12-31 23:00:00'\n",
    "       split_datetime_model = '2019-12-31 23:00:00'\n",
    "    if model == 'MLP4':\n",
    "       start_time_model = '2019-01-01 00:00:00'\n",
    "       end_time_model = '2021-12-31 23:00:00'\n",
    "       split_datetime_model = '2020-12-31 23:00:00'\n",
    "    if model == 'MLP5':\n",
    "       start_time_model = '2020-01-01 00:00:00'\n",
    "       end_time_model = '2022-12-31 23:00:00'\n",
    "       split_datetime_model = '2021-12-31 23:00:00'\n",
    "    if model == 'MLP6':\n",
    "       start_time_model = '2021-01-01 00:00:00'\n",
    "       end_time_model = '2023-12-31 23:00:00'\n",
    "       split_datetime_model = '2022-12-31 23:00:00'\n",
    "\n",
    "    # Create the model output directory name:\n",
    "    output_directory = (model_output_directory + model + '/')\n",
    "  \n",
    "    # Check to see if the output directory exist and if not then create it:\n",
    "    if not os.path.exists(output_directory):\n",
    "       os.makedirs(output_directory)\n",
    "\n",
    "    # Loop over the eight BAs used in this LDRD analysis:\n",
    "    for ba in bas:\n",
    "        \n",
    "        # Run the MLP training for that BA and model training period:\n",
    "        prediction_df, validation_df = tell.train(region = ba,\n",
    "                                                  data_dir = cleaned_ba_data_output_dir,\n",
    "                                                  start_time = start_time_model,\n",
    "                                                  end_time = end_time_model,\n",
    "                                                  split_datetime = split_datetime_model,\n",
    "                                                  save_model = True,\n",
    "                                                  model_output_directory = output_directory)\n",
    "\n",
    "        # Print the model and BA combination to monitor the progress:\n",
    "        print('Model = ', model, ', BA = ', ba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522eade-f01b-4683-9aea-e479761a43a8",
   "metadata": {},
   "source": [
    "## Project Forward Using the Trained MLP Models\n",
    "\n",
    "Use the TELL forward projection function to run the trained MLP models forward in time to project \"future\" loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2425f2-5bd9-4b04-be8e-a7cdef8bf5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more information about the how to use the models to project loads forward in time you can call the help function:\n",
    "help(tell.predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b182f-162b-461c-8a1b-d02dcd7ad37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the MLP forward projection step for a single BA to get a feel of the functionality:\n",
    "pdf = tell.predict(region = 'CISO',\n",
    "                   year = 2023,\n",
    "                   data_dir = weather_data_input_dir,\n",
    "                   datetime_field_name = 'Time_UTC',\n",
    "                   save_prediction = True,\n",
    "                   model_output_directory = '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/trained_mlp_models/MLP1',\n",
    "                   prediction_output_directory = '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/mlp_projections/MLP1')\n",
    "\n",
    "pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9884d35-ba87-4aa0-8739-e066f5237daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the forward projection step iteratively across all training windows and BAs:\n",
    "for model in ['MLP1', 'MLP2', 'MLP3', 'MLP4', 'MLP5', 'MLP6']:\n",
    "\n",
    "    # Set the first forward year for each model:\n",
    "    if model == 'MLP1':\n",
    "       first_forward_year = 2018\n",
    "    if model == 'MLP2':\n",
    "       first_forward_year = 2019\n",
    "    if model == 'MLP3':\n",
    "       first_forward_year = 2020\n",
    "    if model == 'MLP4':\n",
    "       first_forward_year = 2021\n",
    "    if model == 'MLP5':\n",
    "       first_forward_year = 2022\n",
    "    if model == 'MLP6':\n",
    "       first_forward_year = 2023\n",
    "\n",
    "    # Create the model output directory name:\n",
    "    output_directory = (model_output_directory + model + '/')\n",
    "  \n",
    "    # Check to see if the output directory exist and if not then create it:\n",
    "    if not os.path.exists(output_directory):\n",
    "       os.makedirs(output_directory)\n",
    "\n",
    "    # Loop over the eight BAs used in this LDRD analysis:\n",
    "    for ba in bas:\n",
    "\n",
    "        # Loop over the years from the first forward year for that model through 2023:\n",
    "        for year in range(first_forward_year,2024,1):\n",
    "        \n",
    "            # Run the MLP forward projection for that BA, model, and year:\n",
    "            pdf = tell.predict(region = ba,\n",
    "                               year = year,\n",
    "                               data_dir = weather_data_input_dir,\n",
    "                               datetime_field_name = 'Time_UTC',\n",
    "                               save_prediction = True,\n",
    "                               model_output_directory = (model_output_directory + model + '/'),\n",
    "                               prediction_output_directory = (prediction_output_directory + model + '/'))\n",
    "\n",
    "            # Print the model and BA combination to monitor the progress:\n",
    "            print('Model = ', model, ', BA = ', ba, ', Year = ', str(year))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0249f-b898-495b-81d7-7bbc4d33c147",
   "metadata": {},
   "source": [
    "## Compile the Historical and Forward Projection Datasets into a Single .csv File for Each BA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabb7ae-23a8-44ce-9c46-f148ab52f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the eight BAs used in this LDRD analysis:\n",
    "for ba in bas:\n",
    "\n",
    "    # Load in the compiled historical data from the TELL repository:\n",
    "    base_df = pd.read_csv((cleaned_ba_data_output_dir + ba + '_cleaned_historical_data.csv'), index_col=None, header=0)\n",
    "\n",
    "    # Convert the time columns into one datetime variable:\n",
    "    base_df['Time_UTC'] = pd.to_datetime(base_df[['Year', 'Month', 'Day', 'Hour']])\n",
    "    \n",
    "    # Convert the temperature from Kelvin to Fahrenheit:\n",
    "    base_df['T2'] = ((1.8 * (base_df['T2'] - 273)) + 32).round(2)\n",
    "\n",
    "    # Round the population to the nearest whole integer and demand to the nearest tenth:\n",
    "    base_df['Cleaned_Demand_MWh'] = base_df['Cleaned_Demand_MWh'].round(1)\n",
    "    base_df['Total_Population'] = base_df['Total_Population'].round(0).astype(int)\n",
    "    \n",
    "    # Rename the demand and population columns to something simpler:\n",
    "    base_df.rename(columns={'Cleaned_Demand_MWh': 'Demand_MWh', 'Total_Population': 'Population'}, inplace=True)\n",
    "\n",
    "    # Add in the BA code for better tracking:\n",
    "    base_df['BA'] = ba\n",
    "    \n",
    "    # Only keep the columns that are needed:\n",
    "    base_df = base_df[['BA', 'Time_UTC', 'T2', 'Q2', 'SWDOWN', 'GLW', 'WSPD', 'Population', 'Demand_MWh']].copy()\n",
    "\n",
    "    # Loop over the different models and merge in their demand projections iteratively:\n",
    "    for model in ['MLP1', 'MLP2', 'MLP3', 'MLP4', 'MLP5', 'MLP6']:\n",
    "\n",
    "        # Set the first forward year for each model:\n",
    "        if model == 'MLP1':\n",
    "           first_forward_year = 2018\n",
    "        if model == 'MLP2':\n",
    "           first_forward_year = 2019\n",
    "        if model == 'MLP3':\n",
    "           first_forward_year = 2020\n",
    "        if model == 'MLP4':\n",
    "           first_forward_year = 2021\n",
    "        if model == 'MLP5':\n",
    "           first_forward_year = 2022\n",
    "        if model == 'MLP6':\n",
    "           first_forward_year = 2023\n",
    "\n",
    "        # Loop over the years from the first forward year for that model through 2023:\n",
    "        for year in range(first_forward_year,2024,1):\n",
    "\n",
    "            # Load in the MLP projection for that model and year combination:\n",
    "            proj_df = pd.read_csv((prediction_output_directory + model + '/' + str(year) + '/' + ba  + '_' + str(year) + '_mlp_output.csv'), index_col=None, header=0)\n",
    "\n",
    "            # Only keep the columns that are needed:\n",
    "            proj_df = proj_df[['Time_UTC', 'Load']].copy()\n",
    "\n",
    "            # Round the demand to the nearest tenth:\n",
    "            proj_df['Load'] = proj_df['Load'].round(1)\n",
    "    \n",
    "            # Rename the load variable to reflect the model used to generate the projection:\n",
    "            proj_df.rename(columns={'Load': (model + '_MWh')}, inplace=True)\n",
    "\n",
    "            # Convert the time to a datetime variable:\n",
    "            proj_df['Time_UTC'] = pd.to_datetime(proj_df['Time_UTC'])\n",
    "\n",
    "            # Aggregate the output into a new dataframe:\n",
    "            if year == first_forward_year:\n",
    "               aggregate_proj_df = proj_df\n",
    "            else:\n",
    "               aggregate_proj_df = pd.concat([aggregate_proj_df, proj_df])\n",
    "            \n",
    "        # Merge the base_df and proj_df dataframes using common UTC times:\n",
    "        base_df = base_df.merge(aggregate_proj_df, on=['Time_UTC'], how='left')\n",
    "\n",
    "    # Copy the data into an output dataframe:\n",
    "    output_df = base_df.copy()\n",
    "\n",
    "    # Replace NaN values with -999:\n",
    "    output_df = output_df.fillna(-999)\n",
    "\n",
    "    # Set the output file name:\n",
    "    csv_output_filename = (composite_output_directory + ba + '_Composite_Data.csv')\n",
    "\n",
    "    # Write out the dataframe to a .csv file:\n",
    "    output_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "\n",
    "    # Clean up the variables and move to the next BA in the loop:\n",
    "    del base_df, model, first_forward_year, year, proj_df, aggregate_proj_df, output_df, csv_output_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e90bee-f0ff-47fc-a664-3611ffe00785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tell",
   "language": "python",
   "name": "tell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
