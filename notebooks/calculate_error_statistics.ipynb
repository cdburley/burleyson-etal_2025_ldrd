{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e071b84",
   "metadata": {},
   "source": [
    "# Calculate the Error Statistics of the Models Trained Using Evolving Time Windows\n",
    "\n",
    "This notebook takes the composite projection files generated by the \"train_and_run_mlp_models.ipynb\" notebook and calculates the model error statistics for each model in one year blocks of time. The following statistical values, all computed using the sklearn package, are used to evaluate the MLP models:\n",
    "\n",
    "| Parameter | Description | Documentation |\n",
    "| :-: | :- | :-: |\n",
    "| R2 | Coefficient of determination | [sklearn.metrics.r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) |\n",
    "| RMS_ABS | Root-mean-squared of the absolute error | [sklearn.metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) |\n",
    "| RMS_NORM| The RMS_ABS value divided by the mean | [sklearn.metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) |\n",
    "| MAPE| Mean absolute percentage error | [sklearn.metrics.mean_absolute_percentage_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86db683a-70a2-4f89-a1d6-4c6d5f180272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start by importing the TELL package and information about your operating system:\n",
    "import os \n",
    "import tell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e8454-24e1-44f2-bfb7-2f6499e11321",
   "metadata": {},
   "source": [
    "## Set the Directory Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5a9e7b-a9a7-4fdd-957e-2bb5f063afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the data input and output directories:\n",
    "composite_input_directory = '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/composite_projections/'\n",
    "statistics_output_directory = '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0249f-b898-495b-81d7-7bbc4d33c147",
   "metadata": {},
   "source": [
    "## Calculate the Error Statistics by Year for Each BA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfabb7ae-23a8-44ce-9c46-f148ab52f849",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rms_abs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m output_df\u001b[38;5;241m.\u001b[39mloc[counter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProjection_Year\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (year\u001b[38;5;241m-\u001b[39mfirst_forward_year)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     61\u001b[0m output_df\u001b[38;5;241m.\u001b[39mloc[counter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMS_ABS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(year_subset_df[(model \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_MWh\u001b[39m\u001b[38;5;124m'\u001b[39m)], year_subset_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDemand_MWh\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m output_df\u001b[38;5;241m.\u001b[39mloc[counter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMS_NORM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[43mrms_abs\u001b[49m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(year_subset_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDemand_MWh\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     63\u001b[0m output_df\u001b[38;5;241m.\u001b[39mloc[counter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAPE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mean_absolute_percentage_error(year_subset_df[(model \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_MWh\u001b[39m\u001b[38;5;124m'\u001b[39m)], year_subset_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDemand_MWh\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     64\u001b[0m output_df\u001b[38;5;241m.\u001b[39mloc[counter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m r2_score(year_subset_df[(model \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_MWh\u001b[39m\u001b[38;5;124m'\u001b[39m)], year_subset_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDemand_MWh\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rms_abs' is not defined"
     ]
    }
   ],
   "source": [
    "# Initiate a counter and empty dataframe to store the results:\n",
    "counter = 0;\n",
    "output_df = pd.DataFrame()\n",
    "\n",
    "# Loop over the eight BAs used in this LDRD analysis:\n",
    "for ba in ['AZPS', 'BPAT', 'CISO', 'ERCO', 'FPL', 'ISNE', 'PJM', 'WACM']:\n",
    "\n",
    "    # Load in the compiled projection file:\n",
    "    ba_df = pd.read_csv((composite_input_directory + ba + '_Composite_Data.csv'), index_col=None, header=0)\n",
    "\n",
    "    # Replace the missing values with NaN:\n",
    "    ba_df = ba_df.replace(-999.0, np.nan)\n",
    "\n",
    "    # Convert the time to a datetime variable:\n",
    "    ba_df['Time_UTC'] = pd.to_datetime(ba_df['Time_UTC'])\n",
    "\n",
    "    # Extract the year from the Time_UTC variable:\n",
    "    ba_df['Year'] = ba_df['Time_UTC'].dt.year  \n",
    "    \n",
    "    # Loop over all the model training windows:\n",
    "    for model in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6']:\n",
    "    \n",
    "        # Set the first forward year for each model:\n",
    "        if model == 'M1':\n",
    "           first_forward_year = 2018\n",
    "        if model == 'M2':\n",
    "           first_forward_year = 2019\n",
    "        if model == 'M3':\n",
    "           first_forward_year = 2020\n",
    "        if model == 'M4':\n",
    "           first_forward_year = 2021\n",
    "        if model == 'M5':\n",
    "           first_forward_year = 2022\n",
    "        if model == 'M6':\n",
    "           first_forward_year = 2023\n",
    "\n",
    "        # Subset the data to just the variables needed for that model:\n",
    "        subset_df = ba_df[['BA', 'Time_UTC', 'Demand_MWh', (model + '_MWh'), 'Year']].copy()\n",
    "\n",
    "        # Loop over the years from the first forward year for that model through 2023:\n",
    "        for year in range(first_forward_year,2024,1):\n",
    "\n",
    "            # Iterate the counter by one:\n",
    "            counter = counter + 1\n",
    "\n",
    "            # Subset the data to an individual year:\n",
    "            year_subset_df = subset_df.loc[(subset_df['Year'] == year)]\n",
    "\n",
    "            # Drop all rows with missing values:\n",
    "            year_subset_df = year_subset_df.dropna()\n",
    "\n",
    "            # Calculate the difference between the prediction and observation:\n",
    "            year_subset_df['Bias_MWh'] = year_subset_df[(model + '_MWh')] - year_subset_df['Demand_MWh']\n",
    "            year_subset_df['Bias_%'] = 100*((year_subset_df[(model + '_MWh')] - year_subset_df['Demand_MWh']) / year_subset_df['Demand_MWh'])\n",
    "            \n",
    "            # Put the accuracy statistics into the output dataframe:\n",
    "            output_df.loc[counter, 'BA'] = ba\n",
    "            output_df.loc[counter, 'Model'] = model\n",
    "            output_df.loc[counter, 'Year'] = int(year)\n",
    "            output_df.loc[counter, 'Projection_Year'] = (year-first_forward_year)+1\n",
    "            output_df.loc[counter, 'RMS_ABS'] = np.sqrt(mean_squared_error(year_subset_df[(model + '_MWh')], year_subset_df['Demand_MWh'])).round(3)\n",
    "            output_df.loc[counter, 'RMS_NORM'] = ((np.sqrt(mean_squared_error(year_subset_df[(model + '_MWh')], year_subset_df['Demand_MWh'])).round(3)) / np.mean(year_subset_df['Demand_MWh'])).round(3)\n",
    "            output_df.loc[counter, 'MAPE'] = mean_absolute_percentage_error(year_subset_df[(model + '_MWh')], year_subset_df['Demand_MWh']).round(3)\n",
    "            output_df.loc[counter, 'R2'] = r2_score(year_subset_df[(model + '_MWh')], year_subset_df['Demand_MWh']).round(3)\n",
    "            output_df.loc[counter, 'Max_Error_MWh'] = abs(year_subset_df['Bias_MWh']).max().round(1)\n",
    "            output_df.loc[counter, 'Max_Error_%'] = abs(year_subset_df['Bias_%']).max().round(1)\n",
    "\n",
    "            # Clean up and move to the next step in the loop:\n",
    "            del year_subset_df\n",
    "\n",
    "        # Clean up and move to the next step in the loop:\n",
    "        del subset_df, first_forward_year\n",
    "\n",
    "    # Clean up and move to the next step in the loop:\n",
    "    del ba_df\n",
    "\n",
    "# Convert the year variables to integers:\n",
    "output_df['Year'] = output_df['Year'].round(0).astype(int)\n",
    "output_df['Projection_Year'] = output_df['Projection_Year'].round(0).astype(int)\n",
    "\n",
    "# Generate the .csv output file name:\n",
    "csv_output_filename = (statistics_output_directory + 'Error_Statistics_Data.csv')\n",
    "    \n",
    "# Write out the dataframe to a .csv file:\n",
    "output_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "\n",
    "# Return the output_df:\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72747a27-1368-40b6-a898-22fd09fd3a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tell",
   "language": "python",
   "name": "tell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
