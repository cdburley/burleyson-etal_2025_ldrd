{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e071b84",
   "metadata": {},
   "source": [
    "# Calculate the Error Statistics of the Models Trained Using Evolving Time Windows\n",
    "\n",
    "This notebook takes the composite projection files generated by the \"train_and_run_mlp_models.ipynb\" notebook and calculates the model error statistics for each model in one year blocks of time. The following statistical values, all computed using the sklearn package, are used to evaluate the MLP models:\n",
    "\n",
    "| Parameter | Description | Documentation |\n",
    "| :-: | :- | :-: |\n",
    "| R2 | Coefficient of determination | [sklearn.metrics.r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) |\n",
    "| RMS_ABS | Root-mean-squared of the absolute error | [sklearn.metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) |\n",
    "| RMS_NORM| The RMS_ABS value divided by the mean | [sklearn.metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) |\n",
    "| MAPE| Mean absolute percentage error | [sklearn.metrics.mean_absolute_percentage_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db683a-70a2-4f89-a1d6-4c6d5f180272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start by importing the TELL package and information about your operating system:\n",
    "import os \n",
    "import tell\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e8454-24e1-44f2-bfb7-2f6499e11321",
   "metadata": {},
   "source": [
    "## Set the Directory Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a9e7b-a9a7-4fdd-957e-2bb5f063afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the data input and output directories:\n",
    "composite_input_directory = '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/composite_projections/'\n",
    "ba_to_process_input_directory =  '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/'\n",
    "statistics_output_directory = '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f81b90-8b35-42c5-98e9-12123299141b",
   "metadata": {},
   "source": [
    "## Set the List of Balancing Authorities to Analyze\n",
    "\n",
    "BAs used in this analysis are controlled by a master file `balancing_authorities_modeled.yml` stored in the `/data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0cab9-ff34-412d-9502-ed334ddd3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the yml file into a dictionary:\n",
    "with open((ba_to_process_input_directory + 'balancing_authority_modeled.yml'), 'r') as yml:\n",
    "     ba_list = yaml.load(yml, Loader=yaml.FullLoader)\n",
    "     bas = [i for i in ba_list.keys()]\n",
    "\n",
    "# Return the list of BAs to process/plot:\n",
    "bas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0249f-b898-495b-81d7-7bbc4d33c147",
   "metadata": {},
   "source": [
    "## Calculate the Error Statistics by Year for Each BA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabb7ae-23a8-44ce-9c46-f148ab52f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a counter and empty dataframe to store the results:\n",
    "counter = 0;\n",
    "output_df = pd.DataFrame()\n",
    "\n",
    "# Loop over the eight BAs used in this LDRD analysis:\n",
    "for ba in bas:\n",
    "\n",
    "    # Load in the compiled projection file:\n",
    "    ba_df = pd.read_csv((composite_input_directory + ba + '_Composite_Data.csv'), index_col=None, header=0)\n",
    "\n",
    "    # Replace the missing values with NaN:\n",
    "    ba_df = ba_df.replace(-999.0, np.nan)\n",
    "\n",
    "    # Convert the time to a datetime variable:\n",
    "    ba_df['Time_UTC'] = pd.to_datetime(ba_df['Time_UTC'])\n",
    "\n",
    "    # Extract the year from the Time_UTC variable:\n",
    "    ba_df['Year'] = ba_df['Time_UTC'].dt.year  \n",
    "    \n",
    "    # Loop over all the model training windows:\n",
    "    for model in ['MLP1', 'MLP2', 'MLP3', 'MLP4', 'MLP5', 'MLP6', 'MLP7']:\n",
    "    \n",
    "        # Set the first forward year for each model:\n",
    "        if model == 'MLP1':\n",
    "           first_forward_year = 2018\n",
    "        if model == 'MLP2':\n",
    "           first_forward_year = 2019\n",
    "        if model == 'MLP3':\n",
    "           first_forward_year = 2020\n",
    "        if model == 'MLP4':\n",
    "           first_forward_year = 2021\n",
    "        if model == 'MLP5':\n",
    "           first_forward_year = 2022\n",
    "        if model == 'MLP6':\n",
    "           first_forward_year = 2023\n",
    "        if model == 'MLP7':\n",
    "           first_forward_year = 2024\n",
    "\n",
    "        # Subset the data to just the variables needed for that model:\n",
    "        subset_df = ba_df[['BA', 'Time_UTC', 'Demand_MWh', (model + '_MWh'), 'Year']].copy()\n",
    "\n",
    "        # Loop over the years from the first forward year for that model through 2024:\n",
    "        for year in range(first_forward_year,2025,1):\n",
    "\n",
    "            # Iterate the counter by one:\n",
    "            counter = counter + 1\n",
    "\n",
    "            # Subset the data to an individual year:\n",
    "            year_subset_df = subset_df.loc[(subset_df['Year'] == year)]\n",
    "\n",
    "            # Drop all rows with missing values:\n",
    "            year_subset_df = year_subset_df.dropna()\n",
    "\n",
    "            # Calculate the difference between the prediction and observation:\n",
    "            year_subset_df['Bias_MWh'] = year_subset_df[(model + '_MWh')] - year_subset_df['Demand_MWh']\n",
    "            year_subset_df['Bias_%'] = 100*((year_subset_df[(model + '_MWh')] - year_subset_df['Demand_MWh']) / year_subset_df['Demand_MWh'])\n",
    "            \n",
    "            # Put the accuracy statistics into the output dataframe:\n",
    "            output_df.loc[counter, 'BA'] = ba\n",
    "            output_df.loc[counter, 'Model'] = model\n",
    "            output_df.loc[counter, 'Year'] = int(year)\n",
    "            output_df.loc[counter, 'Projection_Year'] = (year-first_forward_year)+1\n",
    "            output_df.loc[counter, 'RMS_ABS'] = np.sqrt(mean_squared_error(year_subset_df[(model + '_MWh')], year_subset_df['Demand_MWh'])).round(3)\n",
    "            output_df.loc[counter, 'RMS_NORM'] = ((np.sqrt(mean_squared_error(year_subset_df[(model + '_MWh')], year_subset_df['Demand_MWh'])).round(3)) / np.mean(year_subset_df['Demand_MWh'])).round(3)\n",
    "            output_df.loc[counter, 'MAPE'] = mean_absolute_percentage_error(year_subset_df[(model + '_MWh')], year_subset_df['Demand_MWh']).round(3)\n",
    "            output_df.loc[counter, 'R2'] = r2_score(year_subset_df[(model + '_MWh')], year_subset_df['Demand_MWh']).round(3)\n",
    "            output_df.loc[counter, 'Max_Error_MWh'] = abs(year_subset_df['Bias_MWh']).max().round(1)\n",
    "            output_df.loc[counter, 'Max_Error_%'] = abs(year_subset_df['Bias_%']).max().round(1)\n",
    "\n",
    "            # Clean up and move to the next step in the loop:\n",
    "            del year_subset_df\n",
    "\n",
    "        # Clean up and move to the next step in the loop:\n",
    "        del subset_df, first_forward_year\n",
    "\n",
    "    # Clean up and move to the next step in the loop:\n",
    "    del ba_df\n",
    "\n",
    "# Convert the year variables to integers:\n",
    "output_df['Year'] = output_df['Year'].round(0).astype(int)\n",
    "output_df['Projection_Year'] = output_df['Projection_Year'].round(0).astype(int)\n",
    "\n",
    "# Generate the .csv output file name:\n",
    "csv_output_filename = (statistics_output_directory + 'Error_Statistics_Data.csv')\n",
    "    \n",
    "# Write out the dataframe to a .csv file:\n",
    "output_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "\n",
    "# Return the output_df:\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72747a27-1368-40b6-a898-22fd09fd3a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tell",
   "language": "python",
   "name": "tell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
