{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd40f4f4-5a80-40b7-94b3-aed136daa9d8",
   "metadata": {},
   "source": [
    "# Plot Time Series Data for a Given Balancing Authority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e597e9-538f-41d4-afa9-a268b10ab1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the packages we need:\n",
    "import os\n",
    "import datetime\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from matplotlib import pyplot \n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f6fe5-0769-4298-887e-7c4cffc64a0d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd887600-32da-46dc-b411-fa63c75f564f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the data and impage input and output directories:\n",
    "ba_data_input_dir =  '/Users/burl878/Documents/Code/code_repos/tell/tell/tell_data/tell_quickstarter_data/outputs/compiled_historical_data/'\n",
    "ba_to_process_input_dir =  '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/'\n",
    "cleaned_ba_data_output_dir =  '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/data/cleaned_historical_data/'\n",
    "image_output_dir =  '/Users/burl878/Documents/Code/code_repos/burleyson-etal_2025_ldrd/figures/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059de424-da3e-4460-81c4-7df133de568a",
   "metadata": {},
   "source": [
    "## Set the List of Balancing Authorities to Analyze\n",
    "\n",
    "BAs used in this analysis are controlled by a master file `balancing_authorities_modeled.yml` stored in the `/data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64309090-3967-472e-a678-036b5e50ae26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AZPS', 'BPAT', 'CISO', 'ERCO', 'FPL', 'ISNE', 'PJM', 'SWPP']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the yml file into a dictionary:\n",
    "with open((ba_to_process_input_dir + 'balancing_authority_modeled.yml'), 'r') as yml:\n",
    "     ba_list = yaml.load(yml, Loader=yaml.FullLoader)\n",
    "     bas = [i for i in ba_list.keys()]\n",
    "\n",
    "# Return the list of BAs to process/plot:\n",
    "bas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1944f0-95d6-4862-9535-d583cef02b21",
   "metadata": {},
   "source": [
    "## Create a Function to Clean the Load Data for a Given Balancing Authority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf793ca-a357-47ee-8a5f-a9f00275b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_load_time_series(ba_to_process: str, start_year: int, end_year: int, ba_data_input_dir: str, cleaned_ba_data_output_dir: str):\n",
    "    # Read in the compiled historical dataset created by the TELL preprocessing:\n",
    "    ba_df = pd.read_csv((ba_data_input_dir + ba_to_process + '_historical_data.csv'))\n",
    "\n",
    "    # Convert the time columns into one datetime variable:\n",
    "    ba_df['Time_UTC'] = pd.to_datetime(ba_df[['Year', 'Month', 'Day', 'Hour']])\n",
    "    \n",
    "    # Create new columns with the cleaned demand and the change in demand between sequential hours:\n",
    "    ba_df['Cleaned_Demand_MWh'] = ba_df['Adjusted_Demand_MWh']\n",
    "    ba_df['Demand_Change_MWh'] = ba_df['Adjusted_Demand_MWh'].diff()\n",
    "\n",
    "    # Replace all hours with demands of 0 MWh with NaN:\n",
    "    ba_df['Cleaned_Demand_MWh'] = ba_df['Cleaned_Demand_MWh'].replace(0, np.nan)\n",
    "\n",
    "    # Replace all rows in which the hour-to-hour change in demand is more than 10 times greater than the mean change with NaN:\n",
    "    ba_df.loc[abs(ba_df['Demand_Change_MWh']) >= (10*(abs(ba_df['Demand_Change_MWh']).mean())), 'Cleaned_Demand_MWh'] = np.nan\n",
    "\n",
    "    # Replace all rows in which the hourly load is more than 5 standard deviations from the mean value with NaN:\n",
    "    ba_df.loc[ba_df['Adjusted_Demand_MWh'] >= ((5*ba_df['Adjusted_Demand_MWh'].std()) + ba_df['Adjusted_Demand_MWh'].mean()), 'Cleaned_Demand_MWh'] = np.nan\n",
    "    \n",
    "    # Set the output file name:\n",
    "    csv_output_filename = (cleaned_ba_data_output_dir + ba_to_process + '_cleaned_historical_data.csv')\n",
    "\n",
    "    # Write out the dataframe to a .csv file:\n",
    "    ba_df.to_csv(csv_output_filename, sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712f3abf-b208-4dc1-911d-0d325d04af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the BAs and clean the load data for each one:\n",
    "for ba in bas:\n",
    "    clean_load_time_series(ba_to_process = ba,\n",
    "                           start_year = 2016,\n",
    "                           end_year = 2023,\n",
    "                           ba_data_input_dir = ba_data_input_dir,\n",
    "                           cleaned_ba_data_output_dir = cleaned_ba_data_output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d184bc-4193-4b2c-96b6-4a4a8d66824a",
   "metadata": {},
   "source": [
    "## Create a Function to Create the Quick Look Plot for a Given Balancing Authority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "086e395e-2bf9-4328-bb14-931b5cba7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_load_weather_time_series(ba_to_plot: str, start_year: int, end_year: int, ba_data_input_dir: str, image_output_dir: str, image_resolution: int, save_images=False):\n",
    "    # Read in the cleaned historical data file:\n",
    "    ba_df = pd.read_csv((cleaned_ba_data_output_dir + ba_to_plot + '_cleaned_historical_data.csv'))\n",
    "\n",
    "    # Convert the time columns into one datetime variable:\n",
    "    ba_df['Time_UTC'] = pd.to_datetime(ba_df[['Year', 'Month', 'Day', 'Hour']])\n",
    "    \n",
    "    # Convert the temperature from Kelvin to Fahrenheit:,\n",
    "    ba_df['T2'] = (1.8 * (ba_df['T2'] - 273)) + 32\n",
    "\n",
    "    # Convert the populations into millions of people:\n",
    "    ba_df['Total_Population'] = ba_df['Total_Population']/1000000\n",
    "\n",
    "    # Count the number of missing load values to gauge the extent of the data cleaning:\n",
    "    missing_data_count = ba_df['Cleaned_Demand_MWh'].isna().sum()\n",
    "    missing_data_percentage = (100*(ba_df['Cleaned_Demand_MWh'].isna().sum()/ba_df.shape[0])).round(3)\n",
    "\n",
    "    # Make the plot:\n",
    "    plt.figure(figsize=(35, 25))\n",
    "    plt.rcParams['font.size'] = 18\n",
    "    plt.subplot(411)\n",
    "    plt.grid(True)\n",
    "    plt.plot(ba_df['Time_UTC'], ba_df['Adjusted_Demand_MWh'], color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.xlim([datetime.date(start_year, 1, 1), datetime.date(end_year+1, 1, 1)])\n",
    "    plt.ylim([(ba_df['Adjusted_Demand_MWh'].min() - 0.1*ba_df['Adjusted_Demand_MWh'].min()), (ba_df['Adjusted_Demand_MWh'].max() + 0.1*ba_df['Adjusted_Demand_MWh'].max())])\n",
    "    plt.ylabel('EIA 930 Adjusted Demand [MWh]', fontsize=18)\n",
    "    plt.title(('Raw Hourly Electricity Demand in ' + ba_to_plot + ' (Peak = ' + str(ba_df['Adjusted_Demand_MWh'].max().round(0)) + ' MWh)'), fontsize=21)\n",
    "    plt.title('a)', loc='left', fontsize=18)\n",
    "\n",
    "    plt.subplot(412)\n",
    "    plt.grid(True)\n",
    "    plt.plot(ba_df['Time_UTC'], ba_df['Cleaned_Demand_MWh'], color='b', linestyle='-', linewidth=0.5)\n",
    "    plt.xlim([datetime.date(start_year, 1, 1), datetime.date(end_year+1, 1, 1)])\n",
    "    plt.ylim([(ba_df['Adjusted_Demand_MWh'].min() - 0.1*ba_df['Adjusted_Demand_MWh'].min()), (ba_df['Adjusted_Demand_MWh'].max() + 0.1*ba_df['Adjusted_Demand_MWh'].max())])\n",
    "    plt.ylabel('Cleaned Demand [MWh]', fontsize=18)\n",
    "    plt.title(('Cleaned Demand in ' + ba_to_plot + ' (Hours Cleaned Percentage = ' + str(missing_data_percentage) + '%)'), fontsize=21)\n",
    "    plt.title('b)', loc='left', fontsize=18)\n",
    "\n",
    "    plt.subplot(413)\n",
    "    plt.grid(True)\n",
    "    plt.plot(ba_df['Time_UTC'], ba_df['T2'], color='r', linestyle='-', linewidth=0.5)\n",
    "    plt.xlim([datetime.date(start_year, 1, 1), datetime.date(end_year+1, 1, 1)])\n",
    "    plt.ylim([(ba_df['T2'].min() - 2), (ba_df['T2'].max() + 2)])\n",
    "    plt.ylabel('Pop-Weighted Temperature [$^\\circ$F]', fontsize=18)\n",
    "    plt.title(('Hourly Temperature in ' + ba_to_plot + ' (Min = ' + str(ba_df['T2'].min().round(1)) + '$^\\circ$F, Max = ' + str(ba_df['T2'].max().round(1)) + '$^\\circ$F)'), fontsize=21)\n",
    "    plt.title('c)', loc='left', fontsize=18)\n",
    "\n",
    "    plt.subplot(414)\n",
    "    plt.grid(True)\n",
    "    plt.plot(ba_df['Time_UTC'], ba_df['Total_Population'], color='g', linestyle='-', linewidth=3)\n",
    "    plt.xlim([datetime.date(start_year, 1, 1), datetime.date(end_year+1, 1, 1)])\n",
    "    plt.ylim([(ba_df['Total_Population'].min() - 0.01*ba_df['Total_Population'].min()), (ba_df['Total_Population'].max() + 0.01*ba_df['Total_Population'].max())])\n",
    "    plt.ylabel('Total Population [Millions]', fontsize=18)\n",
    "    plt.title(('Estimated Population in ' + ba_to_plot + ' (Range = ' + str(1000000*(ba_df['Total_Population'].max() - ba_df['Total_Population'].min()).round(2)) + ')'), fontsize=21)\n",
    "    plt.title('d)', loc='left', fontsize=18)\n",
    "\n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       plt.savefig(os.path.join(image_output_dir + 'BA_Load_Weather_Time_Series_' + ba_to_plot + '.png'), dpi=image_resolution, bbox_inches='tight')\n",
    "       plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858579a4-ac3b-43d6-836c-90bfba64c68b",
   "metadata": {},
   "source": [
    "## Make the Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18593f25-974f-47b6-ac17-a04ffec75d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the BAs and make the plot for each one:\n",
    "for ba in bas:\n",
    "    output_df = plot_load_weather_time_series(ba_to_plot = ba,\n",
    "                                              start_year = 2016,\n",
    "                                              end_year = 2023,\n",
    "                                              ba_data_input_dir = ba_data_input_dir,\n",
    "                                              image_output_dir = image_output_dir, \n",
    "                                              image_resolution = 300, \n",
    "                                              save_images = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65946d4b-d6d5-4937-a3ac-92aad7aa291e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tell",
   "language": "python",
   "name": "tell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
